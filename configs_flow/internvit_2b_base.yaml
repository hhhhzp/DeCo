# lightning.pytorch==2.4.0
seed_everything: true
tags:
  exp: &exp internvit_layer_base
torch_hub_dir: ~/.cache/torch/hub
huggingface_cache_dir: null
trainer:
  default_root_dir: ./internvit_flow_decoder
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: bf16-mixed
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
  logger:
      class_path: lightning.pytorch.loggers.WandbLogger
      init_args:
        save_dir: ./internvit_flow_decoder
        name: *exp
  num_sanity_val_steps: 0
  max_steps: 200100
  val_check_interval: 2500
  check_val_every_n_epoch: null
  log_every_n_steps: 10
  deterministic: null
  inference_mode: true
  use_distributed_sampler: false
  callbacks:
    - class_path: src.callbacks.model_checkpoint.CheckpointHook
      init_args:
        every_n_train_steps: 25000
        save_top_k: -1
        save_last: true
    - class_path: src.callbacks.compute_metrics.ComputeMetricsHook
      init_args:
         compute_fid: true
         fid_feature_dim: 2048
  plugins:
    - src.plugins.bd_env.BDEnvironment
model:
  vae:
    class_path: src.models.autoencoder.pixel.PixelAE
    init_args:
       scale: 1.0
  denoiser:
    class_path: src.models.transformer.dit_t2i_DeCo.PixNerDiT
    init_args:
        in_channels: 3
        patch_size: 16
        num_groups: 16
        hidden_size: &hidden_dim 1024
        hidden_size_x: 32
        num_encoder_blocks: 16
        num_decoder_blocks: 3
        config_path: /apdcephfs/share_300000800/datamultimodal/models/InternVL3-2B
        select_layer: 24
  diffusion_trainer:
    class_path: src.diffusion.flow_matching.training_repa_DeCo.REPATrainer
    init_args:
      lognorm_t: true
      encoder:
        class_path: src.models.encoder.DINOv2
        init_args:
          weight_path: ~/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth
      align_layer: 3
      null_condition_p: 0.0
      proj_denoiser_dim: *hidden_dim
      proj_hidden_dim: *hidden_dim
      proj_encoder_dim: 768
      scheduler: &scheduler src.diffusion.flow_matching.scheduling.LinearScheduler
  diffusion_sampler:
    class_path: src.diffusion.flow_matching.sampling.EulerSampler
    init_args:
      num_steps: 100
      guidance: 1.0
      guidance_interval_min: 1.0
      guidance_interval_max: 1.0
      scheduler: *scheduler
      w_scheduler: src.diffusion.flow_matching.scheduling.LinearScheduler
      guidance_fn: src.diffusion.base.guidance.simple_guidance_fn
      step_fn: src.diffusion.flow_matching.sampling.ode_step_fn
  ema_tracker:
    class_path: src.callbacks.simple_ema.SimpleEMA
    init_args:
      decay: 0.9999
  optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 2e-4
      weight_decay: 0.0
      betas: [0.9, 0.95]
  eval_original_model: true
  diffusion_batch_mul: 4
data:
  train_dataset:
    class_path: src.data.dataset.imagenet.PixHFDataset
    init_args:
      root: /apdcephfs/share_300000800/datamultimodal/zhenpeng_data/imagenet-1k  # /path/to/ImageNet/train/
      resolution: 224
      split: train
  eval_dataset:
    class_path: src.data.dataset.imagenet.PixHFDataset
    init_args:
      root: /apdcephfs/share_300000800/datamultimodal/zhenpeng_data/imagenet-1k  # /path/to/ImageNet/train/
      resolution: 224
      split: validation
  train_batch_size: 16
  train_num_workers: 8
  pred_batch_size: 32
  pred_num_workers: 1